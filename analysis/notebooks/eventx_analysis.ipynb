{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eventx\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from itertools import chain, accumulate\n",
    "\n",
    "from eventx.predictors.predictor_utils import load_predictor\n",
    "from eventx.models.model_utils import batched_predict_json, batched_predict_instances\n",
    "from eventx.predictors import snorkel_predictor, smartdata_predictor\n",
    "from eventx.util import scorer\n",
    "from eventx.util.utils import snorkel_to_ace_format\n",
    "\n",
    "from allennlp.predictors import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_triggers(doc):\n",
    "    return any(entity['entity_type'] == 'trigger' for entity in doc['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE = -1  # or -1 if no GPU is available\n",
    "\n",
    "MODEL_DIR = \"../../data/runs\"\n",
    "\n",
    "SNORKEL = True  # set to False to use smartdata-eventx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SNORKEL:\n",
    "    DATASET_PATH = \"../../data/snorkel_new/test_with_events_and_defaults.jsonl\"\n",
    "    PREDICTOR_NAME = \"snorkel-eventx-predictor\"\n",
    "    ALLENNLP_MODEL = \"snorkel_bert_v6-first_trigger_check_gold/model.tar.gz\"\n",
    "else:\n",
    "    DATASET_PATH = \"../../data/snorkel_new/test_sd4m_with_events.jsonl\"\n",
    "    PREDICTOR_NAME = \"smartdata-eventx-predictor\"\n",
    "    ALLENNLP_MODEL = \"plass_bert_gold/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = load_predictor(MODEL_DIR, PREDICTOR_NAME, CUDA_DEVICE, archive_filename=ALLENNLP_MODEL, weights_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:00, 211.13it/s]\n",
      "Encountered the triggers_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
      "Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
      "Encountered the role_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n"
     ]
    }
   ],
   "source": [
    "instances = predictor._dataset_reader.read(DATASET_PATH) # beware that the read method automatically filters out documents without triggers\n",
    "prediction_instances = batched_predict_instances(predictor, instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_as_json_list = []\n",
    "with io.open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        example = json.loads(line)\n",
    "        doc_as_json_list.append(example)\n",
    "filtered_doc_list = [doc for doc in doc_as_json_list if has_triggers(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SNORKEL:\n",
    "    filtered_doc_list = snorkel_to_ace_format(filtered_doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFKI spree REScorer adapted to Python\n",
    "Grusdt, B., Nehring, J., & Thomas, P. (2018). Bootstrapping patterns for the detection of mobility related events.\n",
    "> For a detected event to count as true positive the predicted event type must be equal to the gold standard event type and the predicted event span must at least be subsumed by the gold standard event span.\n",
    "\n",
    "Schiersch, M., Mironova, V., Schmitt, M., Thomas, P., Gabryszak, A., & Hennig, L. (2020). A german corpus for fine-grained named entity recognition and relation extraction of traffic and industry events. arXiv preprint arXiv:2004.03283.\n",
    "> \\[W\\]e chose a soft matching strategy that counts a predicted relation mention as correct if all predicted arguments also occur in the corresponding gold relation mention, and if all required arguments have been correctly predicted, based on their role, underlying entity, and character offsets / extent. Optional arguments from the gold relation mention that are not contained in the predicted relation mention do not count as errors. In other words, we count a predicted relation mention as correct if it contains all required arguments and is subsumed by or equal to the gold relation mention.\n",
    "\n",
    "The scorer does the following:\n",
    "- It goes through every gold event and looks for a matching/ subsumed predicted event using an EventComparator (see below).\n",
    "- It increments the true positive count if such a predicted event is found and increments the false negative count otherwise.\n",
    "- It treats all remaining predicted events, which were not matched with any of the gold events as false positives.\n",
    "\n",
    "The EventComparator compares two events using the following criteria:\n",
    "- Do the event types match?\n",
    "- Do the spans match or is the predicted event subsumed by the gold event?\n",
    "- Do all the predicted arguments match any of the gold arguments? (I.e. do the argument spans and argument roles match?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_events_batch = [prediction_instance['events'] for prediction_instance in prediction_instances]\n",
    "gold_events_batch = [doc['events'] for doc in filtered_doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obstruction: \tP=0.400\tR=0.333\tF1=0.364\n",
      "\n",
      "Delay: \tP=1.000\tR=1.000\tF1=1.000\n",
      "\n",
      "Accident: \tP=0.333\tR=0.444\tF1=0.381\n",
      "\n",
      "RailReplacementService: \tP=0.400\tR=0.400\tF1=0.400\n",
      "\n",
      "TrafficJam: \tP=0.824\tR=0.875\tF1=0.848\n",
      "\n",
      "CanceledRoute: \tP=0.500\tR=0.400\tF1=0.444\n",
      "\n",
      "CanceledStop: \tP=0.667\tR=0.667\tF1=0.667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scorer.score_events_batch(pred_events_batch, gold_events_batch, allow_subsumption=True, keep_event_matches=True, ignore_span=False, ignore_args=False, ignore_optional_args=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obstruction: \tP=0.600\tR=0.500\tF1=0.545\n",
      "\n",
      "Delay: \tP=1.000\tR=1.000\tF1=1.000\n",
      "\n",
      "Accident: \tP=0.500\tR=0.667\tF1=0.571\n",
      "\n",
      "RailReplacementService: \tP=0.800\tR=0.800\tF1=0.800\n",
      "\n",
      "TrafficJam: \tP=0.824\tR=0.875\tF1=0.848\n",
      "\n",
      "CanceledRoute: \tP=0.500\tR=0.400\tF1=0.444\n",
      "\n",
      "CanceledStop: \tP=0.667\tR=0.667\tF1=0.667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scorer.score_events_batch(pred_events_batch, gold_events_batch, allow_subsumption=True, keep_event_matches=True, ignore_span=False, ignore_args=False, ignore_optional_args=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event extraction evaluation according to Chen et al. 2015\n",
    "\n",
    "Yubo, C., Liheng, X., Kang, L., Daojian, Z., & Jun, Z. (2015). Event extraction via dynamic multi-pooling convolutional neural networks.\n",
    "> A trigger is correct if its event subtype and offsets match those of a reference trigger.\n",
    "\n",
    "> An argument is correctly identified if its event subtype and offsets match those of any of the reference argument mentions.\n",
    "\n",
    "> An argument is correctly classified if its event subtype, offsets and argument role match those of any of the reference argument mentions.\n",
    "\n",
    "Caution:\n",
    "Using the following methods to retrieve the triggers and arguments from the gold data might result in duplicate gold triggers & arguments.\n",
    "This is due to different events possibly sharing the same trigger.\n",
    "The model is not able to distinguish such events and instead fuses them all together, which should result in lower recall.\n",
    "If we remove duplicates from the gold triggers and gold arguments, recall and consequently f1 should be higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_DUPLICATES = True  # change to False if you want to keep duplicate triggers/ arguments from the gold data caused by events sharing the same trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_triggers = scorer.get_triggers(filtered_doc_list)\n",
    "gold_arguments = scorer.get_arguments(filtered_doc_list)\n",
    "pred_triggers = scorer.get_triggers(prediction_instances)\n",
    "pred_arguments = scorer.get_arguments(prediction_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMOVE_DUPLICATES:\n",
    "    gold_triggers = list(set(gold_triggers))\n",
    "    gold_arguments = list(set(gold_arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8947368421052632, 0.8947368421052632, 0.8947368421052632)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_trigger_identification_metrics(gold_triggers, pred_triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8947368421052632, 0.8947368421052632, 0.8947368421052632)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_trigger_classification_metrics(gold_triggers, pred_triggers, accumulated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CanceledStop': (1.0, 1.0, 1.0),\n",
       " 'Delay': (1.0, 1.0, 1.0),\n",
       " 'TrafficJam': (0.8823529411764706, 0.9375, 0.9090909090909091),\n",
       " 'Obstruction': (1.0, 0.8333333333333334, 0.9090909090909091),\n",
       " 'CanceledRoute': (1.0, 0.8, 0.888888888888889),\n",
       " 'RailReplacementService': (0.8, 0.8, 0.8000000000000002),\n",
       " 'Accident': (0.75, 1.0, 0.8571428571428571)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_trigger_classification_metrics(gold_triggers, pred_triggers, accumulated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6237623762376238, 0.78099173553719, 0.6935779816513761)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_argument_identification_metrics(gold_arguments, pred_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5973597359735974, 0.7479338842975206, 0.6642201834862386)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_argument_classification_metrics(gold_arguments, pred_arguments, accumulated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_date': (1.0, 0.25, 0.4),\n",
       " 'end_date': (0.5, 0.3333333333333333, 0.4),\n",
       " 'direction': (0.5454545454545454, 0.7741935483870968, 0.64),\n",
       " 'jam_length': (0.9285714285714286, 1.0, 0.962962962962963),\n",
       " 'location': (0.47107438016528924, 0.6785714285714286, 0.5560975609756097),\n",
       " 'route': (0.75, 1.0, 0.8571428571428571),\n",
       " 'cause': (0.7333333333333333, 0.7333333333333333, 0.7333333333333333),\n",
       " 'end_loc': (0.66, 0.8461538461538461, 0.7415730337078651),\n",
       " 'start_loc': (0.717391304347826, 0.868421052631579, 0.7857142857142858),\n",
       " 'delay': (0.8, 0.5, 0.6153846153846154)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_argument_classification_metrics(gold_arguments, pred_arguments, accumulated=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (eventx)",
   "language": "python",
   "name": "eventx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
